# ===========================================
# src/evaluation.py
# -------------------------------------------
# Ewaluacja modelu EGARCH (out-of-sample)
# - korelacja prognozowanej i rzeczywistej wariancji
# - rolling forecast wykres zmiennoÅ›ci
# ===========================================

import pickle
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from arch import arch_model
from src.data_loader import load_train_test_data
from src.config import LOGS_DIR


def evaluate_egarch(model_filename="egarch_ETH_5m_p1_o1_q1_t.pkl", n_obs: int = 500):
    print(f"ğŸ“‚ WczytujÄ™ model z {model_filename}...")
    payload = pickle.load(open(LOGS_DIR / model_filename, "rb"))
    fitted = payload["model"]
    scale = payload["scale"]

    # --- Wczytanie danych testowych ---
    print("ğŸ“ˆ WczytujÄ™ dane testowe...")
    train_df, test_df = load_train_test_data(load_test=True)

    # --- Wybieramy tylko fragment testu ---
    if len(test_df) > n_obs:
        test_df = test_df.head(n_obs).reset_index(drop=True)
        print(f"ğŸ“ UÅ¼ywam tylko pierwszych {n_obs} Å›wieczek z testu.")
    else:
        print(f"âš ï¸ Test ma mniej niÅ¼ {n_obs} Å›wieczek ({len(test_df)}). UÅ¼ywam caÅ‚oÅ›ci.")

    # --- Standaryzacja testowych log-returnÃ³w ---
    test_returns_std = test_df["log_return"] / scale

    # --- Forecast wariancji (rolling 1-step ahead) ---
    print("ğŸ”® LiczÄ™ rolling forecast wariancji...")
    model = fitted.model
    params = fitted.params

    forecasts = []
    vol = fitted.model.volatility  # tu siedzi prawdziwy EGARCH
    dist_name = "t"

    for i in range(len(test_returns_std)):
        subseries = np.concatenate([fitted.model._y, test_returns_std.values[:i]])
        temp_model = arch_model(
            subseries,
            vol="EGARCH",
            p=vol.p,
            o=vol.o,
            q=vol.q,
            dist=dist_name,
            mean="Constant",
        )
        res = temp_model.fit(
            disp="off", last_obs=len(subseries) - 1, update_freq=0, starting_values=params
        )
        fcast = res.forecast(horizon=1, reindex=False).variance.values[-1, 0]
        forecasts.append(fcast)

    # --- Dopasowanie dÅ‚ugoÅ›ci ---
    test_df = test_df.iloc[:len(forecasts)].copy()
    test_df["var_pred"] = np.array(forecasts)
    test_df["var_real"] = (test_df["log_return"] / scale) ** 2



    # --- Wykres 2:  forecast ---
    plt.figure(figsize=(12, 5))
    plt.plot(test_df["open_time"], np.sqrt(test_df["var_pred"]), label="Prognozowana Ïƒ_t", color="red")
    plt.plot(test_df["open_time"], np.sqrt(test_df["var_real"]), label="Rzeczywista Ïƒ_t", color="black", alpha=0.5)
    plt.title(f"Rolling forecast â€“ zmiennoÅ›Ä‡ warunkowa (ostatnie {n_obs} Å›wieczek)")
    plt.legend()
    plt.tight_layout()
    plt.show()

    print("âœ… Ewaluacja zakoÅ„czona.")


    print("\nğŸ§ª Test diagnostyczny: korelacja przed i po przetasowaniu danych")

    # oryginalna korelacja
    corr_original = np.corrcoef(np.sqrt(test_df["var_pred"]), np.sqrt(test_df["var_real"]))[0, 1]
    print(f"ğŸ“Š Oryginalna korelacja Ïƒ_pred vs Ïƒ_real (dla n_obs={n_obs}): {corr_original:.4f}")

    # shuffle tylko kolumny Ïƒ_real
    shuffled_real = np.random.permutation(np.sqrt(test_df["var_real"]))
    corr_shuffled = np.corrcoef(np.sqrt(test_df["var_pred"]), shuffled_real)[0, 1]
    print(f"ğŸ“‰ Korelacja po przetasowaniu Ïƒ_real: {corr_shuffled:.4f}")

    # spadek w procentach
    drop = (corr_original - corr_shuffled) / abs(corr_original) * 100 if corr_original != 0 else 0
    print(f"ğŸ“‰ Spadek korelacji po shuffle: {drop:.2f}%")

    # scatter
    plt.figure(figsize=(8, 5))
    plt.scatter(np.sqrt(test_df["var_pred"]), shuffled_real, alpha=0.5, s=10, color="purple")
    plt.title(f"Ïƒ_pred vs przetasowana Ïƒ_real (n_obs={n_obs})")
    plt.xlabel("Prognozowana Ïƒ_t")
    plt.ylabel("Rzeczywista Ïƒ_t (shuffle)")
    plt.tight_layout()
    plt.show()


if __name__ == "__main__":
    # moÅ¼esz Å‚atwo zmieniÄ‡ liczbÄ™ obserwacji tutaj:
    evaluate_egarch(n_obs=300)

